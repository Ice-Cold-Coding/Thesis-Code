{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a31aed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import svm\n",
    "import ast\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.multiclass import OneVsRestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ca0db84",
   "metadata": {},
   "source": [
    "### Training on Chest X-ray14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0c9c74a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The file_list will contain the files that will be used for training on the Chest X-ray 14 dataset\n",
    "#The test_list will contain the files that will be used for testing\n",
    "file_list = []\n",
    "test_list = []\n",
    "#Path to the npz files that contain the feature representations\n",
    "directory =  R'D:\\SSD downloads\\Processed Chest X-ray 14'\n",
    "\n",
    "for filename in os.listdir(directory):\n",
    "    #This stores the last 11 npz files for testing, otherwise they are added to the file_list\n",
    "    for number in range(110, 121):\n",
    "        if str(number) in filename:\n",
    "            path = os.path.join(directory, filename)\n",
    "            test_list.append(path)\n",
    "        else:\n",
    "            path = os.path.join(directory, filename)\n",
    "            if os.path.isfile(path):\n",
    "                file_list.append(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0954a968",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The classifiers list will contain the 14 different classifers for each different class\n",
    "classifiers = []\n",
    "#counter is used to stop the model training\n",
    "counter = 0\n",
    "\n",
    "#Loop over the npz files and load them, depending on what key they are stored as, they're loaded into the X_train or y_train \n",
    "#lists, once all the values from a npz file have been placed into the list, they are used to train all 14 classifers\n",
    "for file in file_list:\n",
    "    #These variables are reset for new file that is loaded\n",
    "    loaded_array = np.load(file)\n",
    "    train_image_data = []\n",
    "    train_label = []\n",
    "    #Checking what key the current value from the npz file has\n",
    "    for key in loaded_array:\n",
    "        if \"Label\" in key:\n",
    "            train_label.append(loaded_array[key].tolist())\n",
    "        else:\n",
    "            train_image_data.append(loaded_array[key])    \n",
    "    #Instantiate X_train and y_train\n",
    "    y_train = train_label\n",
    "    y_train = np.array(y_train)\n",
    "    X_train = train_image_data\n",
    "    #y_train.shape[1] = the number of classes\n",
    "    #Loop over the classifiers if they exist train them using their index position within the list\n",
    "    #If they don't exist train them and appende them to the list\n",
    "    for i in range(y_train.shape[1]):\n",
    "        if len(classifiers) > i:\n",
    "            classifiers[i].fit(X_train, y_train[:,i])\n",
    "        else:\n",
    "            clf = logreg= LogisticRegression(solver = \"lbfgs\", C = 1.0, penalty = \"l2\", max_iter = 1000)\n",
    "            clf.fit(X_train, y_train[:,i])\n",
    "            classifiers.append(clf)\n",
    "    #for every batch of 500 data that is used, counter increases by 1\n",
    "    counter += 1\n",
    "    print(counter)\n",
    "    if counter == 20:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7557fbd7",
   "metadata": {},
   "source": [
    "### Testing on Chest X-ray14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "8e27334e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC for label 2: 0.35915409290721156\n",
      "AUC for label 3: 0.4914089347079038\n",
      "AUC for label 7: 0.5419207317073171\n",
      "AUC for label 8: 0.8965955284552846\n",
      "AUC for label 12: 0.5331325301204819\n",
      "AUC for label 2: 0.5379357484620643\n",
      "AUC for label 3: 0.6159183673469388\n",
      "AUC for label 7: 0.5935792349726776\n",
      "AUC for label 8: 0.9791666666666666\n",
      "AUC for label 12: 0.8631790744466801\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "#counter is used to stop the model testing after x amount of iterations \n",
    "counter = 0\n",
    "#AUC score will be stored in roc_auc variable\n",
    "roc_auc = 0\n",
    "\n",
    "\n",
    "for file in test_list:\n",
    "    #These variables are reset for new file that is loaded\n",
    "    X_test = []\n",
    "    y_test = []\n",
    "    loaded_array = np.load(file)\n",
    "    #Checking what key the current value from the npz file has\n",
    "    for key in loaded_array:\n",
    "        if \"Label\" in key:\n",
    "            y_test.append(loaded_array[key].tolist())\n",
    "        else:\n",
    "            X_test.append(loaded_array[key])    \n",
    "    y_test = np.array(y_test)\n",
    "    #The output of the probability predictions for the different classes will be stored in the y_prob variable\n",
    "    y_prob = []\n",
    "    #Generate all the probability predictions from all of the different classifiers\n",
    "    for i in range(y_test.shape[1]):\n",
    "        y_prob.append(classifiers[i].predict_proba(X_test)[:,1])\n",
    "    y_prob = np.array(y_prob).T\n",
    "    #Calculate the AUC-ROC for each label\n",
    "    for i in range(y_test.shape[1]):\n",
    "        #These values represent the indexs of [Effusion, Atelectasis, Consolidation, Cardiomegaly, Edema] in the y_prob[:,i] list\n",
    "        if i in [2,3,8,7,12]:\n",
    "            roc_auc += roc_auc_score(y_test[:, i], y_prob[:, i])\n",
    "            print(f\"AUC for label {i}: {roc_auc_score(y_test[:, i], y_prob[:, i])}\")\n",
    "    counter += 1\n",
    "    if counter == 2:\n",
    "        #AUC average score is calculated based of how many files have been iterated over\n",
    "        roc_auc /= 5*counter\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "2e2c5e7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6411990909793227"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Average AUC score for in-distribution data\n",
    "print(roc_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6112c541",
   "metadata": {},
   "source": [
    "### Testing on CheXpert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "adebfdd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#All the CheXpert files will be loaded into the test_list for out of distribution evaluation\n",
    "test_list = []\n",
    "directory =  R'Q:\\Processed CheXpert'\n",
    "\n",
    "for filename in os.listdir(directory):\n",
    "    path = os.path.join(directory, filename)\n",
    "    if os.path.isfile(path):\n",
    "        test_list.append(path)\n",
    "    #After 5 files have been added to test_list it breaks the loop\n",
    "    if len(test_list) == 5:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "8e343064",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC for label 0: 0.5107090871283011\n",
      "AUC for label 6: 0.4786857974630901\n",
      "AUC for label 7: 0.46519133241124944\n",
      "AUC for label 9: 0.4702868852459016\n",
      "AUC for label 10: 0.3944213923467036\n",
      "AUC for label 0: 0.4769182782283219\n",
      "AUC for label 6: 0.5368579746309003\n",
      "AUC for label 7: 0.5373443983402489\n",
      "AUC for label 9: 0.49955908289241624\n",
      "AUC for label 10: 0.4191271498160851\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "#counter is used to stop the model testing after x amount of iterations \n",
    "counter = 0\n",
    "#AUC score will be stored in roc_auc variable\n",
    "roc_auc = 0\n",
    "\n",
    "\n",
    "for file in test_list:\n",
    "    #These variables are reset for new file that is loaded\n",
    "    X_test = []\n",
    "    y_test = []\n",
    "    loaded_array = np.load(file)\n",
    "    #Checking what key the current value from the npz file has\n",
    "    for key in loaded_array:\n",
    "        if \"Label\" in key:\n",
    "            y_test.append(loaded_array[key].tolist())\n",
    "        else:\n",
    "            X_test.append(loaded_array[key])    \n",
    "    y_test = np.array(y_test)\n",
    "    #The output of the probability predictions for the different classes will be stored in the y_prob variable\n",
    "    y_prob = []\n",
    "    #Generate all the probability predictions from all of the different classifiers\n",
    "    for i in range(y_test.shape[1]):\n",
    "        y_prob.append(classifiers[i].predict_proba(X_test)[:,1])\n",
    "    y_prob = np.array(y_prob).T\n",
    "    #Calculate the AUC-ROC for each label\n",
    "    for i in range(y_test.shape[1]):\n",
    "        #These values represent the indexs of [Edema, Effusion, Atelectasis, Consolidation, Cardiomegaly] in the y_prob[:,i] list\n",
    "        if i in [0,6,7,9,10]:\n",
    "            roc_auc += roc_auc_score(y_test[:, i], y_prob[:, i])\n",
    "            print(f\"AUC for label {i}: {roc_auc_score(y_test[:, i], y_prob[:, i])}\")\n",
    "    counter += 1\n",
    "    if counter == 2:\n",
    "        #AUC score is calculated based of how many files have been iterated over\n",
    "        roc_auc /= 5*counter\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "1e3c903f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4789101378503219"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Average AUC score for out-of-distribution data\n",
    "print(roc_auc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
