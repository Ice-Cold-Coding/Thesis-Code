{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d8d16ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import svm\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bf4e0ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading the self-supervised cxr-50x1-remedis-m model from the Aziz et al, 2022 paper\n",
    "module = hub.load(R'C:\\Users\\tripl\\Downloads\\medical-ai-research-foundations-a-repository-of-medical-foundation-models-1.0.0\\cxr-50x1-remedis-m')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "60089891",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The code executed in 64062.371975660324 seconds.\n"
     ]
    }
   ],
   "source": [
    "#chunksize is set to 500 so that the data is processed in batches of 500\n",
    "chunksize = 500\n",
    "#The csv file containing the names and labels of the filtered data is loaded\n",
    "df = pd.read_csv(\"Filterd_Data_14_Class_Chest X_Ray14\", chunksize=chunksize)\n",
    "#The directory of the chest X-ray14 images \n",
    "path = R\"D:\\Chest X-ray14 Dataset\\images\" \n",
    "\n",
    "\n",
    "#counter keeps track of the number of batches processed \n",
    "counter = 1\n",
    "\n",
    "#The data is loaded in chunks, every chunk the data is fed into the self-supervised model to extract the feature representations\n",
    "#These feature representations are stored in the X_train list with the accompanying encoded integer labels in the y_train list, \n",
    "#these are then saved to a npz file \n",
    "for chunk in df:\n",
    "    #This dictionray will store the values of the batch and will be used to save the values to a npz file\n",
    "    arrays_dict = {}\n",
    "    X_train = []\n",
    "    y_train = []\n",
    "    for index, row in chunk.iterrows():\n",
    "        #Images are loaded in RGB format and resized to (448,448) and converted to a float\n",
    "        image = cv2.imread(path + \"\\\\\" + row[\"Image Index\"], 1)\n",
    "        resized_array = cv2.resize(image,(448, 448))\n",
    "        resized_array = resized_array.astype(np.float32)\n",
    "        resized_array = np.expand_dims(resized_array, axis=0)\n",
    "        #Data is fed into the self-supervised mdoel\n",
    "        embedding_of_image = module(resized_array)\n",
    "        #The output feature representation from model is a (14,14,2048) tensor which is subsequently flattened to a (401408) \n",
    "        #tensor\n",
    "        flattened_tensor = tf.reshape(embedding_of_image, [-1])\n",
    "        array = flattened_tensor.numpy()\n",
    "        arrays_dict[f'{row[\"Image Index\"]}'] = array\n",
    "        label = ast.literal_eval(row[\"Labels\"])\n",
    "        label = np.array(label)\n",
    "        arrays_dict[f'{row[\"Image Index\"]} Label'] = label\n",
    "        #This is the path were the feature representations are saved\n",
    "        np.savez(f'D:\\\\SSD downloads\\\\Processed Chest X-ray 14\\\\Updated Processed Chest X-rays {counter}.npz', **arrays_dict)\n",
    "    counter += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
